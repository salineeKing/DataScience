{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10 - New Topic Identification\n",
    "## Author - Salinee Kingbaisomboon\n",
    "### UW NetID: 1950831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you will use the Keras Reuters newswire topics classification dataset, which consists of:\n",
    "1. This dataset contains 11,228 newswires from Reuters, labeled with over 46 topics.\n",
    "2. Each wire is encoded as a sequence of word indexes. For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    "3. As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "## Instructions\n",
    "1. Read Reuters dataset into training and testing\n",
    "2. Prepare dataset\n",
    "3. Build and compile 3 different models using Keras LSTM ideally improving model at each iteration\n",
    "4. Describe and explain your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # To suppress warning\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare function used in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train: X=(8982,), Y=(8982,)\n",
      "Test: X=(2246,), Y=(2246,)\n"
     ]
    }
   ],
   "source": [
    "# Read Reuters dataset from Keras into training and testing\n",
    "print('Loading data...')\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_vecor_length = 32\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "max_words = 1000\n",
    "num_of_words=10000\n",
    "(data_train, y_train), (data_test, y_test) = reuters.load_data(num_words=num_of_words,\n",
    "                                                         test_split=0.2)\n",
    "print('Train: X=%s, Y=%s' % (data_train.shape, y_train.shape))\n",
    "print('Test: X=%s, Y=%s' % (data_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data set has 46 classes\n"
     ]
    }
   ],
   "source": [
    "# Check how many topics this data set has\n",
    "num_classes = np.max(y_train) + 1\n",
    "print('This data set has' , num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the of of mln loss for plc said at only ended said commonwealth could 1 traders now april 0 a after said from 1985 and from foreign 000 april 0 prices its account year a but in this mln home an states earlier and rise and revs vs 000 its 16 vs 000 a but 3 psbr oils several and shareholders and dividend vs 000 its all 4 vs 000 1 mln agreed largely april 0 are 2 states will billion total and against 000 pct dlrs'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the training data \n",
    "# Checking the first corpus\n",
    "decode_review(data_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build 3 different TensorFlow models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple LSTM for Sequence Classification using Binary Crossentropy as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter the input sequences so that they all have the same length for modeling\n",
    "max_review_length = 400\n",
    "x_train = tensorflow.keras.preprocessing.sequence.pad_sequences(data_train, maxlen=max_review_length)\n",
    "x_test = tensorflow.keras.preprocessing.sequence.pad_sequences(data_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 373,301\n",
      "Trainable params: 373,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct the model\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# View inside the network\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 84s 9ms/sample - loss: -131.9940 - accuracy: 0.0481 - val_loss: -209.2569 - val_accuracy: 0.0467\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 92s 10ms/sample - loss: -267.4406 - accuracy: 0.0481 - val_loss: -329.4305 - val_accuracy: 0.0467\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 92s 10ms/sample - loss: -385.8289 - accuracy: 0.0481 - val_loss: -446.2332 - val_accuracy: 0.0467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18298b11088>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM and Convolutional Neural Network For Sequence Classification using Binary Crossentropy as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 400, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 376,405\n",
      "Trainable params: 376,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Constructthe model\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(num_of_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model2.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(LSTM(100))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# View inside the network\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 32s 4ms/sample - loss: -116.6769 - accuracy: 0.0481 - val_loss: -189.9457 - val_accuracy: 0.0467\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 32s 4ms/sample - loss: -247.2120 - accuracy: 0.0481 - val_loss: -306.3390 - val_accuracy: 0.0467\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 36s 4ms/sample - loss: -360.8061 - accuracy: 0.0481 - val_loss: -418.7618 - val_accuracy: 0.0467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18298c3c7c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple LSTM for Sequence Classification using Categorical Crossentropy as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(data_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(data_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 32)          320000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                4646      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 46)                0         \n",
      "=================================================================\n",
      "Total params: 377,846\n",
      "Trainable params: 377,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Construct the model\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(num_of_words, embedding_vecor_length, input_length=max_words))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(LSTM(100))\n",
    "model3.add(Dense(num_classes))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "# View inside the network\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/3\n",
      "8083/8083 [==============================] - 274s 34ms/sample - loss: 2.4058 - accuracy: 0.3540 - val_loss: 2.4676 - val_accuracy: 0.3315\n",
      "Epoch 2/3\n",
      "8083/8083 [==============================] - 267s 33ms/sample - loss: 2.4047 - accuracy: 0.3540 - val_loss: 2.4700 - val_accuracy: 0.3315\n",
      "Epoch 3/3\n",
      "8083/8083 [==============================] - 261s 32ms/sample - loss: 2.3924 - accuracy: 0.3532 - val_loss: 2.3438 - val_accuracy: 0.3671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x182a12654c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Summary:**\n",
    "1. **Simple LSTM Model using binary_crossentropy as a loss function** yeild accuracy at 4.67% on test data.\n",
    "2. **LSTM and Convolutional Neural Network model using binary_crossentropy as a loss function** yeild accuracy at 4.67% on test data.\n",
    "3. **Simple LSTM model using Categorical Crossentropy as a loss function** yeild accuracy at 38.65% on test data.\n",
    "\n",
    "Therefore, we can see from model **1** and **2** that eventhough we try to improve the model by implementing **CNN**, the model won't improve at all if the **loss function** isn't appropriate. \n",
    "\n",
    "We clearly see from model **3** that the accuracy rate is much better eventhough the hidden layer is less than model **3**.\n",
    "\n",
    "This assignment show the important of how to pick the right **loss function** which then will effect the model significantly.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
