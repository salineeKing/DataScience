{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8 - Wine Classifier\n",
    "## Author - Salinee Kingbaisomboon\n",
    "### UW NetID: 1950831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Use the provided RedWhiteWine.csv file. Include ALL the features with “Class” being your output vector\n",
    "2. Use the provided Simple Perceptron Neural Network notebook to develop a multi-layer feed-forward/backpropagation neural network\n",
    "3. Be able to adjust the following between experiments:\n",
    "    - Learning Rate\n",
    "    - Number of epochs\n",
    "    - ~~Depth of architecture—number of hidden layers between the input and output layers~~ <font color=red>I didn't implement this one.</font>\n",
    "    - Number of nodes in a hidden layer — width of the hidden layers\n",
    "    - (optional) Momentum\n",
    "4. Determine what the best neural network structure and hyperparameter settings results in the best predictive capability\n",
    "\n",
    "**Note:** I implement <font color=blue>**two layers**</font> Neuron Network with flexible **Learning Rate**, **Number of epochs** and **Number of nodes in a hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # To suppress warning\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Functions used in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dimentions and set the weights to random numbers for Two layers network\n",
    "def init_parameters(X, Y, hidden_size):\n",
    "    input_size = X.shape[0] # number of neurons in input layer\n",
    "    output_size = Y.shape[0] # number of neurons in output layer\n",
    "    \n",
    "    W1 = np.random.randn(hidden_size, input_size)*np.sqrt(2/input_size) # weight link between input & hidden layer 1\n",
    "    b1 = np.zeros((hidden_size, 1)) # bias link between hidden layer 2 & output\n",
    "    W2 = np.random.randn(output_size, hidden_size)*np.sqrt(2/hidden_size) # weight link between hidden layer 1 & hidden layer 2\n",
    "    b2 = np.zeros((output_size, 1)) # bias link between input & hidden layer 1\n",
    "    return {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a numerically stable logistic s-shaped definition to call\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    if x.any()>=0:\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x)/(1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two layers network: Forward Prop\n",
    "def fwd_prop(X, params):\n",
    "    Z1 = np.dot(params['W1'], X)+params['b1'] # dot product of the weights and X + bias\n",
    "    A1 = sigmoid(Z1) # predicted vector from hidden layer 1\n",
    "    Z2 = np.dot(params['W2'], A1)+params['b2'] # dot product of the weights and X + bias\n",
    "    y = sigmoid(Z2) # predicted vector from hidden layer 2 (output)\n",
    "    return y, {'Z1': Z1, 'Z2': Z2, 'A1': A1, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predict, actual):\n",
    "    m = actual.shape[1] \n",
    "    cost__ = -np.sum(np.multiply(np.log(predict), actual) + np.multiply((1 - actual), np.log(1 - predict)))/m\n",
    "    return np.squeeze(cost__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two layers network: Backprop\n",
    "def back_prop(X, Y, params, cache):\n",
    "    m = X.shape[1] # number of inputs\n",
    "    dy = cache['y'] - Y\n",
    "    dW2 = (1 / m) * np.dot(dy, np.transpose(cache['A1']))\n",
    "    db2 = (1 / m) * np.sum(dy, axis=1, keepdims=True) # cost of error\n",
    "    dZ1 = np.dot(np.transpose(params['W2']), dy) * (1-np.power(cache['A1'], 2)) # subtract actual from pred weights\n",
    "    dW1 = (1 / m) * np.dot(dZ1, np.transpose(X)) # calc new weight vector\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True) # calc new bias vector\n",
    "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2} # Weight and bias vectors after backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(gradients, params, learning_rate = 1.2):\n",
    "    W1 = params['W1'] - learning_rate * gradients['dW1']\n",
    "    b1 = params['b1'] - learning_rate * gradients['db1']\n",
    "    W2 = params['W2'] - learning_rate * gradients['dW2']\n",
    "    b2 = params['b2'] - learning_rate * gradients['db2']\n",
    "    return {'W1': W1, 'W2': W2, 'b1': b1, 'b2': b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grad_desc(X, Y, learning_rate, hidden_size, num_epochs):\n",
    "    # initialize the parameters\n",
    "    params = init_parameters(X, Y, hidden_size)\n",
    "    cost_ = []\n",
    "    errors = []\n",
    "    for j in range(num_epochs):\n",
    "        y, cache = fwd_prop(X, params) # forward propagate through, get predicted vector\n",
    "        costit = cost(y, Y) # get an initial cost\n",
    "        error = np.mean(np.abs(y - Y)) # get mean of absolute error for each epoch\n",
    "        errors.append(error)\n",
    "        gradients = back_prop(X, Y, params, cache) # get gradient from back propagation\n",
    "        params = update_parameters(gradients, params, learning_rate) # update parameters\n",
    "        cost_.append(costit) # get a new cost after back propagation\n",
    "    return params, cost_, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and perform data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "filename = 'https://library.startlearninglabs.uw.edu/DATASCI420/2019/Datasets/RedWhiteWine.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Class  \n",
       "0      9.4        5      1  \n",
       "1      9.8        5      1  \n",
       "2      9.8        5      1  \n",
       "3      9.8        6      1  \n",
       "4      9.4        5      1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first five rows of the data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>0.246114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality        Class  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378     0.246114  \n",
       "std       0.160787     0.148806     1.192712     0.873255     0.430779  \n",
       "min       2.720000     0.220000     8.000000     3.000000     0.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000     0.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000     0.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000     0.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000     1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Described DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 13)\n",
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "Class                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame's size\n",
    "print(df.shape)\n",
    "# Print DataFrame's data types\n",
    "# Note: we can see that all columns were numeric columns now (after did the onehot-encoded), except the target columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the independent variables (AKA Features) from the dependent labels (AKA Target)\n",
    "targetOutcome = pd.DataFrame(df,columns=['Class'])\n",
    "allFeatures = pd.DataFrame(df,columns=df.columns.difference(['Class']))\n",
    "\n",
    "# Split the Training (90%) and Testing Data (10%)\n",
    "X, XX, Y, YY = train_test_split(allFeatures, targetOutcome, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler for normalization\n",
    "standard_scaler = StandardScaler().fit(X)\n",
    "\n",
    "# Normalize the training dataset\n",
    "X = standard_scaler.transform(X)\n",
    "\n",
    "# Normalize the test dataset\n",
    "XX = standard_scaler.transform(XX)\n",
    "\n",
    "# Convert label data into numpy array\n",
    "Y = Y.to_numpy() # .values for older version\n",
    "YY = YY.to_numpy() # .values for older version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 5000\n",
    "depth_of_architecture = 1 # number of hidden layers between the input and output layers\n",
    "hidden_size = 5 # width of the hidden layers\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params, cost_, errors = run_grad_desc(X, Y, learning_rate, hidden_size, num_epochs)\n",
    "plt.plot(cost_)\n",
    "plt.title('Plot the loss array (cost function)')\n",
    "plt.xlabel('Training')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 98.04%\n"
     ]
    }
   ],
   "source": [
    "# get the mean of accuracy rate for all epochs\n",
    "error = np.mean(errors)\n",
    "accuracy = (1 - error) * 100\n",
    "print(\"Training Accuracy \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Summary:**\n",
    "The best 2-layered neural network structure with following hyperparameters:\n",
    "- Learning Rrate = 0.01\n",
    "- Number of epochs = 5000\n",
    "- Width of the Hidden Layers = 5\n",
    "\n",
    "Note: I manually run the code with some arbitary settings and this structure gave me the best **Accuracy Prediction** (98.04% on the Training data).\n",
    "Note 2: I tried to run in a loop to change the settings but it does take a very long time.  \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
